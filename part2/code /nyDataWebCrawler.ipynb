{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "good!\n",
      "good!\n",
      "Reason:  [Errno 111] Connection refused\n",
      "Reason:  [Errno 111] Connection refused\n",
      "good!\n",
      "good!\n",
      "good!\n",
      "good!\n",
      "good!\n",
      "good!\n"
     ]
    }
   ],
   "source": [
    "#FOR QUERY = FACEBOOK\n",
    "\n",
    "import urllib.request as ur\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "r = requests.get(\"https://api.nytimes.com/svc/search/v2/articlesearch.json?query=facebook&api-key=26b729b1adb141039783bc4258e431b9\")\n",
    "print(r)\n",
    "data =r.json()\n",
    "for g in data['response']['docs']:\n",
    "    pg =g['web_url']\n",
    "    try:\n",
    "        page = ur.urlopen(pg)\n",
    "    except HTTPError as e:\n",
    "        print('Error code: ', e.code)\n",
    "    except URLError as e:\n",
    "        print('Reason: ', e.reason)\n",
    "    else:\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        print('good!')\n",
    "        for data in soup.findAll('p',{'class':'story-body-text'}):\n",
    "            openFile = open(\"fbNYTIMESdata\", \"a\")\n",
    "            \n",
    "           # print(data.get_text())\n",
    "            appendFile = openFile.write(data.get_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://www.nytimes.com/2018/03/27/technology/facebooks-zuckerberg-said-to-agree-to-testify-before-congress-over-data-privacy.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/03/21/technology/facebook-zuckerberg-data-privacy.html\n",
      "good!\n",
      "https://www.nytimes.com/reuters/2018/03/28/business/28reuters-facebook-cambridge-analytica.html\n",
      "good!\n",
      "https://www.nytimes.com/reuters/2018/03/27/business/27reuters-facebook-cambridge-analytica.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/03/27/technology/ap-us-tec-facebook-zuckerberg-congress.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/03/19/business/dealbook/is-it-time-for-more-adult-supervision-at-facebook.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/04/05/us/ap-us-facebook-privacy-scandal.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/03/25/technology/ap-us-tec-facebook-data-collection-ads-the-latest.html\n",
      "good!\n",
      "https://www.nytimes.com/reuters/2018/04/05/technology/05reuters-facebook-privacy-australia.html\n",
      "good!\n",
      "https://www.nytimes.com/reuters/2018/03/26/business/26reuters-facebook-cambridge-analytica-apology.html\n",
      "good!\n"
     ]
    }
   ],
   "source": [
    "#query = \"MARK + ZUCKERBERG+DATA+Breach\n",
    "import urllib.request as ur\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?query=mark+zuckerberg+data+breach&api-key=26b729b1adb141039783bc4258e431b9\"\n",
    "r = requests.get(url)\n",
    "print(r)\n",
    "data =r.json()\n",
    "for g in data['response']['docs']:\n",
    "    pg =g['web_url']\n",
    "    print(pg)\n",
    "    try:\n",
    "        page = ur.urlopen(pg)\n",
    "    except HTTPError as e:\n",
    "        print('Error code: ', e.code)\n",
    "    except URLError as e:\n",
    "        print('Reason: ', e.reason)\n",
    "    else:\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        print('good!')\n",
    "        for data in soup.findAll('p',{'class':'story-body-text'}):\n",
    "            openFile = open(\"MarkZuckerberDataBreach\", \"a\")\n",
    "            \n",
    "           # print(data.get_text())\n",
    "           # print(\" \")\n",
    "            appendFile = openFile.write(data.get_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://www.nytimes.com/reuters/2018/04/04/business/04reuters-facebook-privacy-australia.html\n",
      "good!\n",
      "https://www.nytimes.com/reuters/2018/04/05/technology/05reuters-facebook-privacy-australia.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/04/06/world/asia/ap-as-indonesia-facebook.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/03/27/world/asia/ap-as-new-zealand-facebook.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/04/01/opinion/facebook-lax-privacy-rules.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/03/26/us/ap-facebook-cambridge-analytica-investigations-glance.html\n",
      "good!\n",
      "https://www.nytimes.com/aponline/2018/03/26/technology/ap-tec-facebook-cambridge-analytica.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/03/29/opinion/facebook-privacy-zuckerberg-society.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/03/28/technology/facebook-privacy-security-settings.html\n",
      "good!\n",
      "https://www.nytimes.com/2018/03/26/technology/ftc-facebook-investigation-cambridge-analytica.html\n",
      "good!\n"
     ]
    }
   ],
   "source": [
    "#query = \"privacy +  facebook + socialMedia\n",
    "import urllib.request as ur\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?query=privacy+socialmedia+facebook&api-key=26b729b1adb141039783bc4258e431b9\"\n",
    "r = requests.get(url)\n",
    "print(r)\n",
    "data =r.json()\n",
    "for g in data['response']['docs']:\n",
    "    pg =g['web_url']\n",
    "    print(pg)\n",
    "    try:\n",
    "        page = ur.urlopen(pg)\n",
    "    except HTTPError as e:\n",
    "        print('Error code: ', e.code)\n",
    "    except URLError as e:\n",
    "        print('Reason: ', e.reason)\n",
    "    else:\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        print('good!')\n",
    "        for data in soup.findAll('p',{'class':'story-body-text'}):\n",
    "            openFile = open(\"privacyintrusion\", \"a\")\n",
    "            \n",
    "           # print(data.get_text())\n",
    "           # print(\" \")\n",
    "            appendFile = openFile.write(data.get_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing text file to CSV \n",
    "\n",
    "import csv\n",
    "\n",
    "with open('fb', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\"\\t\") for line in stripped if line)\n",
    "    with open('fb.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('word', 'count'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
